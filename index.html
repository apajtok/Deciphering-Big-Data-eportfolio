<html>
	<head>
		<title>Adrienn Pajtók Deciphering Big Data Portfolio</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>

				<!-- Banner -->
					<section id="banner" class="major">
						<div class="inner">
							<header class="major">
								<h1>ePortfolio by Adrienn Pajtók</h1>
							</header>
							<div class="content">
								<p>Deciphering Big Data portfolio<br />
								August 2024 - October 2024.</p>
					
				<!-- Main -->
					<div id="main">

						<!-- One -->
							<section id="one" class="tiles">
								<article>
									<span class="image">
										<img src="images/pic01.jpg" alt="" />
									</span>
									<header class="major">
										<h3>Discussion 1</a></h3>
										<p>Big data architectures manage large and diverse datasets using various processing techniques, including batch and real-time data handling, analytics, and machine learning. Key components of these architectures are:
<ul>
  <li>Data Sources like databases and IoT devices.</li>
  <li>Data Storage solutions, such as Azure Data Lake, store extensive datasets.</li>
  <li>Batch Processing tools (e.g., Hadoop, Spark) prepare data for analysis over longer intervals.</li>
  <li>Real-Time Message Ingestion with tools like Azure IoT Hub processes live data streams.</li>
  <li>Stream Processing analyzes real-time data via services like Azure Stream Analytics.</li>
  <li>Machine Learning models generated by platforms like Azure ML provide predictive insights.</li>
  <li>Analytical Data Stores like Azure Synapse Analytics enable structured querying.</li>
  <li>Analysis and Reporting tools, including Power BI, deliver insights.</li>
  <li>Orchestration manages workflows with tools such as Azure Data Factory.</li>
</ul>
<br>
To manage data latency and accuracy, architectures like Lambda separate data into batch (cold) and real-time (hot) paths, whereas Kappa, a simplified approach, relies on a single stream processing path. Lambda’s dual path can create complexity but enables low-latency responses in critical scenarios. In contrast, Kappa handles all data in real-time with reduced complexity.
The Internet of Things (IoT), encompassing connected devices from smartphones to industrial sensors, relies on event-driven architectures for processing data in real-time. (Zoiner Tejada (n.d.) As discussed by Hasan, M. K. et al. (2024) processing in IoT includes storing event data, real-time analytics for anomaly detection, handling device notifications, and machine learning. However, IoT data security remains challenging due to resource limitations in many devices. Solutions like identity-based and blockchain authentication protocols are employed to secure data exchanges. 
<br>
Cloud computing is foundational for IoT, supporting storage, processing, and analytics, thus playing a crucial role in powering IoT solutions. Future developments focus on enhancing security and scalability for increasing IoT data flows. Cloud Computing has a pivotal role to power IoT Solutions IoT. (Gondosubroto, R, 2024)
</p>
<h4>References</h4> 
<p>
  Zoiner Tejada (n.d.). Big data architectures - Azure Architecture Center. [online] learn.microsoft.com. Available at: https://learn.microsoft.com/en-us/azure/architecture/databases/guide/big-data-architectures. <br>
  Hasan, M. K. et al. (2024) A Survey on Key Agreement and Authentication Protocol for Internet of Things Application. IEEE access. [Online] 1261642–61666. <br>
  Gondosubroto, R. (2024) Internet of Things from Scratch : Build IoT Solutions for Industry 4. 0 with ESP32, Raspberry Pi, and AWS. First edition. Birmingham, England: Packt Publishing Ltd.
</p>
								<article>
									<span class="image">
										<img src="images/pic02.jpg" alt="" />
									</span>
									<header class="major">
										<h3><a>Web Scraping</a></h3>
										<p>For a data analyst to be able to read and understand web pages is a crucial. BeautifulSoup is a Python library which is used to read, download, format data. (its current version is bs4, the 4th version). bs4 is used to gather and parse data from HTML or XML documents.  Request, Processing through a communication Protocol and Response are the steps in parsing and IPC (Inter Process Communication).
The requests library is a popular Python library for making HTTP requests. I used Colab (cloud-based environment) for this task.
(Tirthajyoti Sarkar and Shubhadeep Roychowdhury, 2019) Write a web scraping script in Python using the key word 'Data Scientist' and parse this data into either an XML or JSON file. Perform the web scraping with the beautifulsoup4 and Request program modules. </p>
								<a href="https://github.com/apajtok/Deciphering-Big-Data-eportfolio/blob/main/Web%20Scraping">Code here</a></p>
								<a href="https://github.com/apajtok/Deciphering-Big-Data-eportfolio/blob/main/data_scientist_results.json">Json file here</a></p>
<h4>References</h4> 
<p>
Tirthajyoti Sarkar and Shubhadeep Roychowdhury (2019). Data wrangling with Python : creating actionable data from raw sources. Birmingham, Uk: Packt Publishing Ltd.
</p>


										
									</header>
								</article>
								<article>
									<span class="image">
										<img src="images/pic03.jpg" alt="" />
									</span>
								</article>
								<article>
									<span class="image">
										<img src="images/pic04.jpg" alt="" />
									</span>
									<header class="major">
									<h3>Data Cleaning </a></h3>
										<p>Follow the instructions on page 150-151 of the Data Wrangling with Python textbook to manually produce data files mn.csv and mn_headers.csv and replace acronym headers with readable headers. (Kazil & Jarmul, 2016). Data cleaning entails confirming the accuracy and reliability of quantitative data by assessing its quality. This process incorporates practical techniques such as reviewing data coding, verifying data entry, examining distributions, and detecting outliers. (Huxley, 2020) </p>  
<a href="https://github.com/apajtok/Deciphering-Big-Data-eportfolio/blob/main/replace%20headers%20script.py">Script here</a></p>
<a href="https://github.com/apajtok/Deciphering-Big-Data-eportfolio/blob/main/mn_headers_updated.csv">Updated file here</a></p>
<p>. Study the complete process listed on pages 199-209 of the Data Wrangling with Python textbook </p>  
<a href="https://github.com/apajtok/Deciphering-Big-Data-eportfolio/blob/main/replace%20headers%20script.py">Script here</a></p>
<h4>References</h4> 
<p>
Huxley, K., Atkinson, P,. Delamont, S., Cermut,
A., Sakshaug, J. &. Williams, R. (2020) Data cleaning. Sage Foundation. 
</p>
									</header>
								</article>
								<article>
									<span class="image">
										<img src="images/pic05.jpg" alt="" />
									</span>
									<header class="major">
                                                                                <h3>Automation And Scaling </a></h3>
										<p>Automating tasks requires a structured approach to ensure reliability and efficiency. Firstly, each task must be clarified, including the start time, time limits, required inputs, expected outputs, and criteria for success. In case of failure contingency plan is needed, and outline what should steps should be post-completion. The steps for automation include:

Break down the problem into manageable parts.
Define inputs, processes, and success criteria for each part.
Locate necessary resources and schedule tasks.
Develop and test code with sample data.
Clean and document the code.
Implement logging to track errors and successful completions.
Submit, test, and refine code as needed.
Replace manual steps with automation.
Monitor logs for errors and make adjustments.
Establish a regular log-checking schedule.
Common issues to watch include database errors, script bugs, timeouts, edge cases, and hardware limitations.</p>
<h4>References</h4> 
<p>
Kazil, J. and Jarmul, K. (2016). Data Wrangling with Python. ‘O’Reilly Media, Inc.’
</p>
									</header>
								</article>
								<article>
									<span class="image">
										<img src="images/pic06.jpg" alt="" />
									</span>
									<header class="major">
                                                                                <h3>Normalisation </a></h3>

  <h3>1. First Normal Form (1NF)</h3>
  <p><strong>Eliminate repeating groups:</strong> The original table has repeating groups for Exam Boards and Teacher Name. To achieve 1NF, I separated these into new tables.</p>

  <p><strong>New tables:</strong></p>
  <ul>
    <li><strong>Students:</strong> Student Number (PK), Student Name, Date of Birth, Support</li>
    <li><strong>Courses:</strong> Course Name (PK)</li>
    <li><strong>Exams:</strong> Exam ID (PK), Student Number (FK), Course Name (FK), Exam Score</li>
    <li><strong>Exam Boards:</strong> Board ID (PK), Exam Board Name</li>
    <li><strong>Teachers:</strong> Teacher ID (PK), Teacher Name</li>
    <li><strong>CourseExams:</strong> CourseExam ID (PK), Course Name (FK), Exam ID (FK), Board ID (FK)</li>
    <li><strong>CourseTeachers:</strong> CourseTeacher ID (PK), Course Name (FK), Teacher ID (FK)</li>
  </ul>

  <p><strong>Assign primary keys (PK) and foreign keys (FK):</strong> I've indicated these in the table descriptions above.</p>

  <h3>2. Second Normal Form (2NF)</h3>
  <p>1NF and... <strong>Eliminate redundant data:</strong> In the <code>Exams</code> table, <code>Exam Score</code> depends on the combination of <code>Student Number</code> and <code>Course Name</code> (the composite primary key). This means we need to create a new table to remove this redundancy.</p>

  <p><strong>Create a new table:</strong></p>
  <ul>
    <li><strong>StudentCourses:</strong> StudentCourse ID (PK), Student Number (FK), Course Name (FK), Exam Score</li>
  </ul>

  <p><strong>Remove <code>Exam Score</code> from the <code>Exams</code> table.</strong></p>

  <h3>3. Third Normal Form (3NF)</h3>
  <p>2NF and... <strong>Eliminate columns not dependent on the key:</strong> In the <code>Students</code> table, <code>Support</code> might be related to a student's course or a specific learning need, not just the student themselves. We'll create new tables to capture this.</p>

  <p><strong>Create new tables:</strong></p>
  <ul>
    <li><strong>Support:</strong> Support ID (PK), Support Type</li>
    <li><strong>StudentSupport:</strong> StudentSupport ID (PK), Student Number (FK), Support ID (FK)</li>
  </ul>

  <p><strong>Remove <code>Support</code> from the <code>Students</code> table.</strong></p>

  <h3>Final Tables in 3NF:</h3>
  <ul>
    <li><strong>Students:</strong> Student Number (PK), Student Name, Date of Birth</li>
    <li><strong>Courses:</strong> Course Name (PK)</li>
    <li><strong>Exams:</strong> Exam ID (PK), Student Number (FK), Course Name (FK)</li>
    <li><strong>Exam Boards:</strong> Board ID (PK), Exam Board Name</li>
    <li><strong>Teachers:</strong> Teacher ID (PK), Teacher Name</li>
    <li><strong>CourseExams:</strong> CourseExam ID (PK), Course Name (FK), Exam ID (FK), Board ID (FK)</li>
    <li><strong>CourseTeachers:</strong> CourseTeacher ID (PK), Course Name (FK), Teacher ID (FK)</li>
    <li><strong>StudentCourses:</strong> StudentCourse ID (PK), Student Number (FK), Course Name (FK), Exam Score</li>
    <li><strong>Support:</strong> Support ID (PK), Support Type</li>
    <li><strong>StudentSupport:</strong> StudentSupport ID (PK), Student Number (FK), Support ID (FK)</li>
  </ul>

  <p>This 3NF structure eliminates redundancy and ensures data integrity.</p>
<a href="https://github.com/apajtok/Deciphering-Big-Data-eportfolio/blob/main/1NF.pdf">1NF</a></p>
<a href="https://github.com/apajtok/Deciphering-Big-Data-eportfolio/blob/main/2NF.html">2NF</a></p>
<a href="https://github.com/apajtok/Deciphering-Big-Data-eportfolio/blob/main/3NF.pdf">3NF</a></p>
									</header>
								</article>
							</section>

						<!-- Two -->
							<section id="two">
								<div class="inner">
									<header class="major">
										<h2><a>A Relational Database System Built Using SQLite. o</h2>
									</header>
									<p>Nullam et orci eu lorem consequat tincidunt vivamus et sagittis libero. Mauris aliquet magna magna sed nunc rhoncus pharetra. Pellentesque condimentum sem. In efficitur ligula tate urna. Maecenas laoreet massa vel lacinia pellentesque lorem ipsum dolor. Nullam et orci eu lorem consequat tincidunt. Vivamus et sagittis libero. Mauris aliquet magna magna sed nunc rhoncus amet pharetra et feugiat tempus.</p>
									<ul class="actions">
										<li><a href="landing.html" class="button next">Get Started</a></li>
									</ul>
								</div>
							</section>
									<header class="major">
										<h3><a>Connecting To Database In SQLite</a></h3>
										<p>For a data analyst to be able to read and understand web pages is a crucial. Python has commonly used library to read, download, format data. This library is called BeautifulSoup (its current version is bs4, the 4th version). bs4 is used to get data from HTML or XML documents and it supports parsers. (Tirthajyoti Sarkar and Shubhadeep Roychowdhury, 2019)</p>
								<a href="https://github.com/apajtok/Deciphering-Big-Data-eportfolio/blob/main/Web%20Scraping">Code here</a></p>
								<a href="https://github.com/apajtok/Deciphering-Big-Data-eportfolio/blob/main/data_scientist_results.json">Json file here</a></p>
                                                        	</header>
					</div>
									<header class="major">
										<h3><a>Discussion 2</a></h3>
										<p>For a data analyst to be able to read and understand web pages is a crucial. Python has commonly used library to read, download, format data. This library is called BeautifulSoup (its current version is bs4, the 4th version). bs4 is used to get data from HTML or XML documents and it supports parsers. (Tirthajyoti Sarkar and Shubhadeep Roychowdhury, 2019)</p>
								<a href="https://github.com/apajtok/Deciphering-Big-Data-eportfolio/blob/main/Web%20Scraping">Code here</a></p>
								<a href="https://github.com/apajtok/Deciphering-Big-Data-eportfolio/blob/main/data_scientist_results.json">Json file here</a></p>
                                                        	</header>
													<header class="major">
										<h3><a>API Security Requirements</a></h3>
										<p>For a data analyst to be able to read and understand web pages is a crucial. Python has commonly used library to read, download, format data. This library is called BeautifulSoup (its current version is bs4, the 4th version). bs4 is used to get data from HTML or XML documents and it supports parsers. (Tirthajyoti Sarkar and Shubhadeep Roychowdhury, 2019)</p>
								<a href="https://github.com/apajtok/Deciphering-Big-Data-eportfolio/blob/main/Web%20Scraping">Code here</a></p>
								<a href="https://github.com/apajtok/Deciphering-Big-Data-eportfolio/blob/main/data_scientist_results.json">Json file here</a></p>
                                                        	</header>
									<header class="major">
										<h3><a>Critical Evaluation Of The Disaster Recovery System Called The “Grandfather-Father-Son" GFS Backup </a></h3>
										<p>For a data analyst to be able to read and understand web pages is a crucial. Python has commonly used library to read, download, format data. This library is called BeautifulSoup (its current version is bs4, the 4th version). bs4 is used to get data from HTML or XML documents and it supports parsers. (Tirthajyoti Sarkar and Shubhadeep Roychowdhury, 2019)</p>
								<a href="https://github.com/apajtok/Deciphering-Big-Data-eportfolio/blob/main/Web%20Scraping">Code here</a></p>
								<a href="https://github.com/apajtok/Deciphering-Big-Data-eportfolio/blob/main/data_scientist_results.json">Json file here</a></p>
                                                        	</header>
																		<header class="major">
										<h3><a>Evaluation Of The Final Project (Unit 11) vs. The Initial Project Proposal (Unit 6</a></h3>
										<p>For a data analyst to be able to read and understand web pages is a crucial. Python has commonly used library to read, download, format data. This library is called BeautifulSoup (its current version is bs4, the 4th version). bs4 is used to get data from HTML or XML documents and it supports parsers. (Tirthajyoti Sarkar and Shubhadeep Roychowdhury, 2019)</p>
								<a href="https://github.com/apajtok/Deciphering-Big-Data-eportfolio/blob/main/Web%20Scraping">Code here</a></p>
								<a href="https://github.com/apajtok/Deciphering-Big-Data-eportfolio/blob/main/data_scientist_results.json">Json file here</a></p>
  
                                                        	</header>	
										<header class="major">
                                                                                <h3>Impact On Professional/Personal Development </a></h3>
										<h3><a href="landing.html" class="link">Reflection</a></h3>
										<p>Reflection on landing page</p>
									</header>																		
																		
																		
																		
																		
								</header>	
										<header class="major">
                                                                                <h3>Reflection </a></h3>
										<h3><a href="landing.html" class="link">Reflection</a></h3>
										<p>Reflection on landing page</p>
									</header>		
										
										
										
										
										<!-- Contact -->
							</section>
							<section class="split">
								<section>
									<div class="contact-method">
										<span class="icon solid alt fa-envelope"></span>
										<h3>Email</h3>
										<a href="#">apajtok@gmail.com</a>
									</div>
								</section>
								<section>
									<div class="contact-method">
										<span class="icon solid alt fa-home"></span>
										<h3>Address</h3>
										<span>3 Rothsay Road<br />
										Bedford, TN 00000<br />
										United Kingdom</span>
									</div>
								</section>
							</section>
						</div>
					</section>

				<!-- Footer -->
					<footer id="footer">
						<div class="inner">
							<ul class="copyright">
								<li>&copy; Untitled</li><li>Design: <a href="https://html5up.net">HTML5 UP</a></li>
							</ul>
						</div>
					</footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
