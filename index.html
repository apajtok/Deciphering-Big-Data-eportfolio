<html>
	<head>
		<title>Adrienn Pajtók Deciphering Big Data Portfolio</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>

				<!-- Banner -->
					<section id="banner" class="major">
						<div class="inner">
							<header class="major">
								<h1>ePortfolio by Adrienn Pajtok</h1>
							</header>
							<div class="content">
								<p>Deciphering Big Data portfolio<br />
								August 2024 - October 2024.</p>
					
				<!-- Main -->
					<div id="main">

						<!-- One -->
							<section id="one" class="tiles">
								<article>
									<span class="image">
										<img src="images/pic01.jpg" alt="" />
									</span>
									<header class="major">
										<h3>Discussion 1</a></h3>
										<p>Big data architectures manage large and diverse datasets using various processing techniques, including batch and real-time data handling, analytics, and machine learning. Key components of these architectures are:
<ul>
  <li>Data Sources like databases and IoT devices.</li>
  <li>Data Storage solutions, such as Azure Data Lake, store extensive datasets.</li>
  <li>Batch Processing tools (e.g., Hadoop, Spark) prepare data for analysis over longer intervals.</li>
  <li>Real-Time Message Ingestion with tools like Azure IoT Hub processes live data streams.</li>
  <li>Stream Processing analyzes real-time data via services like Azure Stream Analytics.</li>
  <li>Machine Learning models generated by platforms like Azure ML provide predictive insights.</li>
  <li>Analytical Data Stores like Azure Synapse Analytics enable structured querying.</li>
  <li>Analysis and Reporting tools, including Power BI, deliver insights.</li>
  <li>Orchestration manages workflows with tools such as Azure Data Factory.</li>
</ul>
<br>
To manage data latency and accuracy, architectures like Lambda separate data into batch (cold) and real-time (hot) paths, whereas Kappa, a simplified approach, relies on a single stream processing path. Lambda’s dual path can create complexity but enables low-latency responses in critical scenarios. In contrast, Kappa handles all data in real-time with reduced complexity.
The Internet of Things (IoT), encompassing connected devices from smartphones to industrial sensors, relies on event-driven architectures for processing data in real-time. (Zoiner Tejada (n.d.) As discussed by Hasan, M. K. et al. (2024) processing in IoT includes storing event data, real-time analytics for anomaly detection, handling device notifications, and machine learning. However, IoT data security remains challenging due to resource limitations in many devices. Solutions like identity-based and blockchain authentication protocols are employed to secure data exchanges. 
<br>
Cloud computing is foundational for IoT, supporting storage, processing, and analytics, thus playing a crucial role in powering IoT solutions. Future developments focus on enhancing security and scalability for increasing IoT data flows. Cloud Computing has a pivotal role to power IoT Solutions IoT. (Gondosubroto, R, 2024)
</p>
<h4>References</h4> 
<p>
  Zoiner Tejada (n.d.). Big data architectures - Azure Architecture Center. [online] learn.microsoft.com. Available at: https://learn.microsoft.com/en-us/azure/architecture/databases/guide/big-data-architectures. <br>
  Hasan, M. K. et al. (2024) A Survey on Key Agreement and Authentication Protocol for Internet of Things Application. IEEE access. [Online] 1261642–61666. <br>
  Gondosubroto, R. (2024) Internet of Things from Scratch : Build IoT Solutions for Industry 4. 0 with ESP32, Raspberry Pi, and AWS. First edition. Birmingham, England: Packt Publishing Ltd.
</p>
								<article>
									<span class="image">
										<img src="images/pic02.jpg" alt="" />
									</span>
									<header class="major">
										<h3><a>Web Scraping</a></h3>
										<p>For a data analyst to be able to read and understand web pages is a crucial. BeautifulSoup is a Python library which is used to read, download, format data. (its current version is bs4, the 4th version). bs4 is used to gather and parse data from HTML or XML documents.  Request, Processing through a communication Protocol and Response are the steps in parsing and IPC (Inter Process Communication).
The requests library is a popular Python library for making HTTP requests. I used Colab (cloud-based environment) for this task.
(Tirthajyoti Sarkar and Shubhadeep Roychowdhury, 2019) Write a web scraping script in Python using the key word 'Data Scientist' and parse this data into either an XML or JSON file. Perform the web scraping with the beautifulsoup4 and Request program modules. </p>
								<a href="https://github.com/apajtok/Deciphering-Big-Data-eportfolio/blob/main/Web%20Scraping">Code here</a></p>
								<a href="https://github.com/apajtok/Deciphering-Big-Data-eportfolio/blob/main/data_scientist_results.json">Json file here</a></p>
<h4>References</h4> 
<p>
Tirthajyoti Sarkar and Shubhadeep Roychowdhury (2019). Data wrangling with Python : creating actionable data from raw sources. Birmingham, Uk: Packt Publishing Ltd.
</p>


										
									</header>
								</article>
								<article>
									<span class="image">
										<img src="images/pic03.jpg" alt="" />
									</span>
								</article>
								<article>
									<span class="image">
										<img src="images/pic04.jpg" alt="" />
									</span>
									<header class="major">
									<h3>Data Cleaning </a></h3>
										<p>Follow the instructions on page 150-151 of the Data Wrangling with Python textbook to manually produce data files mn.csv and mn_headers.csv and replace headers. (Kazil & Jarmul, 2016). Data cleaning entails confirming the accuracy and reliability of quantitative data by assessing its quality. This process incorporates practical techniques such as reviewing data coding, verifying data entry, examining distributions, and detecting outliers. (Huxley, 2020) </p>  
<a href="https://github.com/apajtok/Deciphering-Big-Data-eportfolio/blob/main/replace%20headers%20script.py">Script here</a></p>
<a href="https://github.com/apajtok/Deciphering-Big-Data-eportfolio/blob/main/mn_headers_updated.csv">Updated file here</a></p>
<p>Follow the instructions on page 150-151 of the Data Wrangling with Python textbook to manually produce data files mn.csv and mn_headers.csv (Kazil & Jarmul, 2016). Data cleaning entails confirming the accuracy and reliability of quantitative data by assessing its quality. This process incorporates practical techniques such as reviewing data coding, verifying data entry, examining distributions, and detecting outliers. (Huxley, 2020) </p>  
<a href="https://github.com/apajtok/Deciphering-Big-Data-eportfolio/blob/main/replace%20headers%20script.py">Script here</a></p>
<h4>References</h4> 
<p>
Huxley, K., Atkinson, P,. Delamont, S., Cermut,
A., Sakshaug, J. &. Williams, R. (2020) Data cleaning. Sage Foundation. Available from:
https://docs.microsoft.com/en-us/azure/architecture/data-guide/big-data
</p>
									</header>
								</article>
								<article>
									<span class="image">
										<img src="images/pic05.jpg" alt="" />
									</span>
									<header class="major">
                                                                                <h3>Automation And Scaling </a></h3>
										<h3><a href="landing.html" class="link">Consequat</a></h3>
										<p>Automation and scaling</p>
									</header>
								</article>
								<article>
									<span class="image">
										<img src="images/pic06.jpg" alt="" />
									</span>
									<header class="major">
                                                                                <h3>Normalisation </a></h3>
										<h3><a href="landing.html" class="link">Etiam</a></h3>
										<p>Feugiat amet tempus</p>
									</header>
								</article>
							</section>

						<!-- Two -->
							<section id="two">
								<div class="inner">
									<header class="major">
										<h2><a>A Relational Database System Built Using SQLite. o</h2>
									</header>
									<p>Nullam et orci eu lorem consequat tincidunt vivamus et sagittis libero. Mauris aliquet magna magna sed nunc rhoncus pharetra. Pellentesque condimentum sem. In efficitur ligula tate urna. Maecenas laoreet massa vel lacinia pellentesque lorem ipsum dolor. Nullam et orci eu lorem consequat tincidunt. Vivamus et sagittis libero. Mauris aliquet magna magna sed nunc rhoncus amet pharetra et feugiat tempus.</p>
									<ul class="actions">
										<li><a href="landing.html" class="button next">Get Started</a></li>
									</ul>
								</div>
							</section>
									<header class="major">
										<h3><a>Connecting To Database In SQLite</a></h3>
										<p>For a data analyst to be able to read and understand web pages is a crucial. Python has commonly used library to read, download, format data. This library is called BeautifulSoup (its current version is bs4, the 4th version). bs4 is used to get data from HTML or XML documents and it supports parsers. (Tirthajyoti Sarkar and Shubhadeep Roychowdhury, 2019)</p>
								<a href="https://github.com/apajtok/Deciphering-Big-Data-eportfolio/blob/main/Web%20Scraping">Code here</a></p>
								<a href="https://github.com/apajtok/Deciphering-Big-Data-eportfolio/blob/main/data_scientist_results.json">Json file here</a></p>
                                                        	</header>
					</div>
									<header class="major">
										<h3><a>Discussion 2</a></h3>
										<p>For a data analyst to be able to read and understand web pages is a crucial. Python has commonly used library to read, download, format data. This library is called BeautifulSoup (its current version is bs4, the 4th version). bs4 is used to get data from HTML or XML documents and it supports parsers. (Tirthajyoti Sarkar and Shubhadeep Roychowdhury, 2019)</p>
								<a href="https://github.com/apajtok/Deciphering-Big-Data-eportfolio/blob/main/Web%20Scraping">Code here</a></p>
								<a href="https://github.com/apajtok/Deciphering-Big-Data-eportfolio/blob/main/data_scientist_results.json">Json file here</a></p>
                                                        	</header>
													<header class="major">
										<h3><a>API Security Requirements</a></h3>
										<p>For a data analyst to be able to read and understand web pages is a crucial. Python has commonly used library to read, download, format data. This library is called BeautifulSoup (its current version is bs4, the 4th version). bs4 is used to get data from HTML or XML documents and it supports parsers. (Tirthajyoti Sarkar and Shubhadeep Roychowdhury, 2019)</p>
								<a href="https://github.com/apajtok/Deciphering-Big-Data-eportfolio/blob/main/Web%20Scraping">Code here</a></p>
								<a href="https://github.com/apajtok/Deciphering-Big-Data-eportfolio/blob/main/data_scientist_results.json">Json file here</a></p>
                                                        	</header>
									<header class="major">
										<h3><a>Critical Evaluation Of The Disaster Recovery System Called The “Grandfather-Father-Son" GFS Backup </a></h3>
										<p>For a data analyst to be able to read and understand web pages is a crucial. Python has commonly used library to read, download, format data. This library is called BeautifulSoup (its current version is bs4, the 4th version). bs4 is used to get data from HTML or XML documents and it supports parsers. (Tirthajyoti Sarkar and Shubhadeep Roychowdhury, 2019)</p>
								<a href="https://github.com/apajtok/Deciphering-Big-Data-eportfolio/blob/main/Web%20Scraping">Code here</a></p>
								<a href="https://github.com/apajtok/Deciphering-Big-Data-eportfolio/blob/main/data_scientist_results.json">Json file here</a></p>
                                                        	</header>
																		<header class="major">
										<h3><a>Evaluation Of The Final Project (Unit 11) vs. The Initial Project Proposal (Unit 6</a></h3>
										<p>For a data analyst to be able to read and understand web pages is a crucial. Python has commonly used library to read, download, format data. This library is called BeautifulSoup (its current version is bs4, the 4th version). bs4 is used to get data from HTML or XML documents and it supports parsers. (Tirthajyoti Sarkar and Shubhadeep Roychowdhury, 2019)</p>
								<a href="https://github.com/apajtok/Deciphering-Big-Data-eportfolio/blob/main/Web%20Scraping">Code here</a></p>
								<a href="https://github.com/apajtok/Deciphering-Big-Data-eportfolio/blob/main/data_scientist_results.json">Json file here</a></p>
  
                                                        	</header>	
										<header class="major">
                                                                                <h3>Impact On Professional/Personal Development </a></h3>
										<h3><a href="landing.html" class="link">Reflection</a></h3>
										<p>Reflection on landing page</p>
									</header>																		
																		
																		
																		
																		
								</header>	
										<header class="major">
                                                                                <h3>Reflection </a></h3>
										<h3><a href="landing.html" class="link">Reflection</a></h3>
										<p>Reflection on landing page</p>
									</header>		
										
										
										
										
										<!-- Contact -->
							</section>
							<section class="split">
								<section>
									<div class="contact-method">
										<span class="icon solid alt fa-envelope"></span>
										<h3>Email</h3>
										<a href="#">apajtok@gmail.com</a>
									</div>
								</section>
								<section>
									<div class="contact-method">
										<span class="icon solid alt fa-home"></span>
										<h3>Address</h3>
										<span>3 Rothsay Road<br />
										Bedford, TN 00000<br />
										United Kingdom</span>
									</div>
								</section>
							</section>
						</div>
					</section>

				<!-- Footer -->
					<footer id="footer">
						<div class="inner">
							<ul class="copyright">
								<li>&copy; Untitled</li><li>Design: <a href="https://html5up.net">HTML5 UP</a></li>
							</ul>
						</div>
					</footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
